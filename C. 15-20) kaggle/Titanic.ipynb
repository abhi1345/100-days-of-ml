{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import preprocessing\nfrom sklearn.ensemble import ExtraTreesClassifier\nle = preprocessing.LabelEncoder()\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n\n\ntrain = pd.read_csv(\"../input/train.csv\")\ntrain = train.fillna(method='ffill').fillna(method='bfill')\n\n\nfor col in train:\n    currcol = train[col]\n    boo = np.issubdtype(currcol.dtype, np.number)\n    if not boo:\n        labels = list(set(currcol))\n        le.fit(labels)\n        newcol = le.transform(currcol)\n        train[col] = newcol\nx_train = train[['Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked']]\ny_train = train['Survived']\ntrain.head()\n\n\nmodel = ExtraTreesClassifier(n_estimators=1000, min_samples_leaf=2)\nmodel.fit(x_train, y_train)\nmodel.predict([[0,3,108,1,22.0,1,0,523,7.2500,81]])\n\n\ntest = pd.read_csv('../input/test.csv')\nids = list(test['PassengerId'])\ntest = test.fillna(method='ffill').fillna(method='bfill')\nfor col in test:\n    currcol = test[col]\n    labels = list(set(currcol))\n    le.fit(labels)\n    newcol = le.transform(currcol)\n    test[col] = newcol\nx_test = test[['Pclass','Name','Sex','Age','SibSp','Parch','Ticket','Fare','Cabin','Embarked']]\npredictions = list(model.predict(x_test))\n\ntwodarray = []\nfor i in range(418):\n    l =  [ids[i], predictions[i]]\n    twodarray.append(l)\ndf = pd.DataFrame(twodarray, columns=['PassengerId', 'Survived'])\ndf = df[['PassengerId', 'Survived']]\n\ndf.to_csv('Titanic_Solution.csv', index=False)\n\nprint('Done')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "211d6e6918960408b8de5903cff3e402cdf75d82"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "312f47f7653d30959ca86736587b1ea3be567340"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2ee1c18d86f242260ce19005d230acac8d7be40b"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}